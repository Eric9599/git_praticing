{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-10T16:19:17.567975Z",
     "start_time": "2026-02-10T16:19:12.550634Z"
    }
   },
   "source": [
    "import pdfplumber\n",
    "from llm_guard.input_scanners import PromptInjection, InvisibleText\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from llm_guard.input_scanners.prompt_injection import MatchType\n",
    "import pytesseract\n",
    "from docx import Document\n",
    "from PIL import Image\n",
    "from langchain_core.documents import Document as LCDocument\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "from deepeval.metrics import (\n",
    "    FaithfulnessMetric,\n",
    "    AnswerRelevancyMetric,\n",
    "    ContextualRecallMetric,\n",
    "    ContextualPrecisionMetric,\n",
    "    ContextualRelevancyMetric\n",
    ")\n",
    "\n",
    "from openai import OpenAI\n",
    "from qdrant_client import QdrantClient, models\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from typing import List\n",
    "import requests\n",
    "import uuid\n",
    "import gc\n",
    "import tqdm"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:16:30.819111Z",
     "start_time": "2026-02-10T16:16:30.780925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_list = [\"1.pdf\", \"2.pdf\", \"3.pdf\", \"4.png\", \"5.docx\"]\n",
    "file_path = \"HW\"\n",
    "EMBEDDING_API_URL = \"http://ws-04.wade0426.me/embed\"\n",
    "QDRANT_URL = \"http://localhost:6333\"\n",
    "COLLECTION_NAME = \"rag_homework_day7_api\"\n",
    "LLM_BASE_URL = \"https://ws-06.huannago.com/v1\"\n",
    "RERANKER_MODEL_PATH = os.path.expanduser(\"../day6/Qwen3-Reranker-0.6B\")\n",
    "LLM_API_KEY = \"day6hw\"\n",
    "LLM_MODEL_NAME = \"gemma-3-27b-it\"\n",
    "PREDICT_INPUT = \"HW/questions.csv\"\n",
    "PREDICT_OUPUT = \"HW/output.csv\""
   ],
   "id": "5e5d809f28b772e8",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:13:52.296390Z",
     "start_time": "2026-02-10T16:13:31.508373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_list = [\"1.pdf\", \"2.pdf\", \"3.pdf\", \"4.png\", \"5.docx\"]\n",
    "file_path = \"HW\"\n",
    "docs_content = {}\n",
    "\n",
    "print(\"--- é–‹å§‹ IDP è™•ç† ---\")\n",
    "\n",
    "for file_name in file_list:\n",
    "    full_path = os.path.join(file_path, file_name)\n",
    "\n",
    "    if not os.path.exists(full_path):\n",
    "        print(f\"* æ‰¾ä¸åˆ°æª”æ¡ˆ: {file_name}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"æ­£åœ¨è™•ç†: {file_name}...\")\n",
    "    extracted_text = \"\"\n",
    "\n",
    "    # ==========================================\n",
    "    # 1. é‡å° PDF (åŒ…å« 3.pdf çš„è¡¨æ ¼è™•ç†)\n",
    "    # ==========================================\n",
    "    if file_name.endswith(\".pdf\"):\n",
    "        try:\n",
    "            with pdfplumber.open(full_path) as pdf:\n",
    "                for page in pdf.pages:\n",
    "                    text = page.extract_text()\n",
    "                    if text:\n",
    "                        extracted_text += text + \"\\n\"\n",
    "\n",
    "                    tables = page.extract_tables()\n",
    "                    for table in tables:\n",
    "                        table_str = \"\"\n",
    "                        for row in table:\n",
    "                            # æ¸…æ´— row ä¸­çš„ Noneï¼Œè½‰ç‚ºå­—ä¸²\n",
    "                            cleaned_row = [str(cell) if cell is not None else \"\" for cell in row]\n",
    "                            table_str += \" | \".join(cleaned_row) + \"\\n\"\n",
    "\n",
    "                        extracted_text += \"\\n[è¡¨æ ¼å…§å®¹é–‹å§‹]\\n\" + table_str + \"\\n[è¡¨æ ¼å…§å®¹çµæŸ]\\n\"\n",
    "\n",
    "                print(f\"âœ… [{file_name}] PDF (å«è¡¨æ ¼) æå–æˆåŠŸ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ PDF è®€å–éŒ¯èª¤ {file_name}: {e}\")\n",
    "\n",
    "    # ==========================================\n",
    "    # 2. é‡å° PNG (é‡å° 4.png çš„ OCR è™•ç†)\n",
    "    # ==========================================\n",
    "    elif file_name.endswith(\".png\"):\n",
    "        try:\n",
    "            image = Image.open(full_path)\n",
    "            ocr_text = pytesseract.image_to_string(image, lang='chi_tra+eng')\n",
    "\n",
    "            extracted_text = ocr_text\n",
    "            print(f\"âœ… [{file_name}] OCR è¾¨è­˜æˆåŠŸ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ OCR å¤±æ•— {file_name}: {e}\")\n",
    "            print(\"æç¤º: è«‹ç¢ºèªæ˜¯å¦å·²å®‰è£ Tesseract è»Ÿé«”ä¸¦è¨­å®šç’°å¢ƒè®Šæ•¸\")\n",
    "\n",
    "    # ==========================================\n",
    "    # 3. é‡å° DOCX (5.docx)\n",
    "    # ==========================================\n",
    "    elif file_name.endswith(\".docx\"):\n",
    "        try:\n",
    "            doc = Document(full_path)\n",
    "            for para in doc.paragraphs:\n",
    "                extracted_text += para.text + \"\\n\"\n",
    "            print(f\"âœ… [{file_name}] Word è®€å–æˆåŠŸ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Word è®€å–éŒ¯èª¤ {file_name}: {e}\")\n",
    "\n",
    "    # --- å­˜å…¥çµæœ ---\n",
    "    if extracted_text.strip():\n",
    "        docs_content[file_name] = extracted_text\n",
    "    else:\n",
    "        print(f\"âš ï¸ è­¦å‘Š: {file_name} æ²’æœ‰æå–åˆ°ä»»ä½•æ–‡å­—\")\n",
    "\n",
    "print(\"-\" * 30)"
   ],
   "id": "8be1e2c46e3fceb0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [4.png] OCR è¾¨è­˜æˆåŠŸ\n",
      "æ­£åœ¨è™•ç†: 5.docx...\n",
      "âœ… [5.docx] Word è®€å–æˆåŠŸ\n",
      "------------------------------\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:13:52.322728Z",
     "start_time": "2026-02-10T16:13:52.314696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. åˆå§‹åŒ–åˆ‡åˆ†å™¨\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # åˆ†éš”ç¬¦å„ªå…ˆé †åºï¼šé›™æ›è¡Œ(æ®µè½) > å–®æ›è¡Œ(è¡Œ) > ç©ºæ ¼ > ç©ºå­—ä¸²\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    chunk_size=500,    # æ¯å€‹å€å¡Šå¤§ç´„ 500 å€‹å­—å…ƒ\n",
    "    chunk_overlap=50,  # æ»‘å‹•è¦–çª—ï¼šä¿ç•™ 50 å€‹å­—å…ƒçš„é‡ç–Šï¼Œé¿å…èªæ„æ–·è£‚\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "# 2. æº–å‚™å°‡ä½ çš„å­—å…¸è½‰æ›æˆ LangChain çš„ Document ç‰©ä»¶\n",
    "all_documents = []\n",
    "\n",
    "for filename, text in docs_content.items():\n",
    "    # å»ºç«‹ Document ç‰©ä»¶ï¼Œè¨˜å¾—æŠŠæª”åæ”¾å…¥ metadataï¼Œé€™æ˜¯ä¹‹å¾Œ RAG å¼•ç”¨ä¾†æº(Source)çš„é—œéµ\n",
    "    doc = LCDocument(\n",
    "        page_content=text,\n",
    "        metadata={\"source\": filename}\n",
    "    )\n",
    "    all_documents.append(doc)\n",
    "\n",
    "# 3. åŸ·è¡Œåˆ‡åˆ†\n",
    "split_docs = text_splitter.split_documents(all_documents)"
   ],
   "id": "e067dbb876bbc86d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:13:53.869111Z",
     "start_time": "2026-02-10T16:13:52.323070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scanner = PromptInjection(threshold=0.5, match_type=MatchType.FULL)\n",
    "for filename, text_content in docs_content.items():\n",
    "    print(f\"æ­£åœ¨æƒæ {filename} ...\")\n",
    "\n",
    "    # ç¢ºä¿å…§å®¹æ˜¯å­—ä¸²ï¼Œé¿å…éŒ¯èª¤\n",
    "    if not isinstance(text_content, str):\n",
    "        text_content = str(text_content)\n",
    "\n",
    "    # åŸ·è¡Œæƒæ\n",
    "    sanitized_text, is_valid, score = scanner.scan(text_content)\n",
    "\n",
    "    if not is_valid:\n",
    "        print(f\"*  è­¦å‘Šï¼šåœ¨ [{filename}] ç™¼ç¾éš±è—æ–‡å­—ï¼(Score: {score})\")\n",
    "    else:\n",
    "        print(f\"OKï¼š[{filename}] æœªç™¼ç¾éš±è—æ–‡å­—ã€‚\")"
   ],
   "id": "2bfafa1a871e2d78",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKï¼š[5.docx] æœªç™¼ç¾éš±è—æ–‡å­—ã€‚\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:13:53.911697Z",
     "start_time": "2026-02-10T16:13:53.898354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available():\n",
    "    device_obj = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device_obj = torch.device(\"mps\")\n",
    "else:\n",
    "    device_obj = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"â³ ä½¿ç”¨è£ç½®: {device_obj}\")"
   ],
   "id": "8561629d9add3c24",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ ä½¿ç”¨è£ç½®: mps\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:14:00.756264Z",
     "start_time": "2026-02-10T16:13:53.912116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomAPIEmbeddings(Embeddings):\n",
    "    def __init__(self, api_url):\n",
    "        self.api_url = api_url\n",
    "\n",
    "    def _call_api(self, texts: List[str]) -> List[List[float]]:\n",
    "        data = {\n",
    "            \"texts\": texts,\n",
    "            \"normalize\": True,\n",
    "            \"batch_size\": 32\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.post(self.api_url, json=data, timeout=60)\n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                return result.get('embeddings', [])\n",
    "            else:\n",
    "                print(f\"âŒ API Error Code: {response.status_code}\")\n",
    "                return []\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ API Exception: {e}\")\n",
    "            return []\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self._call_api(texts)\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        results = self._call_api([text])\n",
    "        if results and len(results) > 0:\n",
    "            return results[0]\n",
    "        return []\n",
    "\n",
    "\n",
    "print(f\"* åˆå§‹åŒ– Embedding API ({EMBEDDING_API_URL})...\")\n",
    "embedding_model = CustomAPIEmbeddings(EMBEDDING_API_URL)\n",
    "try:\n",
    "    print(\"* æ¸¬è©¦ Embedding API é€£ç·š...\")\n",
    "    test_vec = embedding_model.embed_query(\"æ¸¬è©¦\")\n",
    "    if test_vec:\n",
    "        print(f\"âœ… API é€£ç·šæˆåŠŸï¼å‘é‡ç¶­åº¦: {len(test_vec)}\")\n",
    "    else:\n",
    "        print(\"âŒ API é€£ç·šå¤±æ•—ï¼Œå›å‚³ç‚ºç©º\")\n",
    "        exit()\n",
    "except Exception as e:\n",
    "    print(f\"âŒ API æ¸¬è©¦ç™¼ç”Ÿä¾‹å¤–éŒ¯èª¤: {e}\")\n",
    "    exit()"
   ],
   "id": "9558d81a60af039c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API é€£ç·šæˆåŠŸï¼å‘é‡ç¶­åº¦: 4096\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:14:00.851931Z",
     "start_time": "2026-02-10T16:14:00.792847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleLLMClient:\n",
    "    def __init__(self, base_url, model_name, api_key):\n",
    "        self.client = OpenAI(base_url=base_url, api_key=api_key)\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.3,\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"LLM Error: {e}\")\n",
    "            return \"Error generating response.\"\n",
    "\n",
    "\n",
    "print(\"â³ åˆå§‹åŒ– LLM Client...\")\n",
    "llm_client = SimpleLLMClient(LLM_BASE_URL, LLM_MODEL_NAME, LLM_API_KEY)\n"
   ],
   "id": "bc89be58c5f629d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ åˆå§‹åŒ– LLM Client...\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:14:00.898316Z",
     "start_time": "2026-02-10T16:14:00.863330Z"
    }
   },
   "cell_type": "code",
   "source": "client = QdrantClient(url=QDRANT_URL)",
   "id": "d14de3997c7c333b",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:14:00.915303Z",
     "start_time": "2026-02-10T16:14:00.898766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def init_qdrant_collection(documents):\n",
    "    \"\"\"\n",
    "    å»ºç«‹ Qdrant Collection ä¸¦å¯«å…¥å·²åˆ‡åˆ†çš„è³‡æ–™\n",
    "    Args:\n",
    "        documents: List[Document] (ç”± LangChain åˆ‡åˆ†å¥½çš„æ–‡ä»¶åˆ—è¡¨)\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. æª¢æŸ¥è³‡æ–™æ˜¯å¦ç‚ºç©º\n",
    "    if not documents:\n",
    "        print(\"âš ï¸ å‚³å…¥çš„æ–‡ä»¶åˆ—è¡¨ç‚ºç©ºï¼Œè·³éå¯«å…¥ã€‚\")\n",
    "        return\n",
    "\n",
    "    print(f\"ğŸ”„ æ­£åœ¨é‡ç½®é›†åˆ {COLLECTION_NAME}...\")\n",
    "    try:\n",
    "        client.delete_collection(COLLECTION_NAME)\n",
    "        print(f\"* å·²åˆªé™¤èˆŠé›†åˆ {COLLECTION_NAME}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2. å»ºç«‹æ–°çš„ Collection\n",
    "    # æ³¨æ„: size=4096 å¿…é ˆèˆ‡ä½ ä½¿ç”¨çš„ Embedding æ¨¡å‹ç¶­åº¦ä¸€è‡´\n",
    "    # (ä¾‹å¦‚ OpenAI text-embedding-3-large æ˜¯ 3072, text-embedding-ada-002 æ˜¯ 1536)\n",
    "    print(f\"â³ å»ºç«‹æ–° Collection: {COLLECTION_NAME}...\")\n",
    "    client.create_collection(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        vectors_config={\n",
    "            \"dense\": models.VectorParams(\n",
    "                distance=models.Distance.COSINE,\n",
    "                size=1536, # <--- è«‹ç¢ºèªé€™è£¡æ˜¯å¦ç¬¦åˆä½ çš„ Embedding æ¨¡å‹ç¶­åº¦ï¼\n",
    "            ),\n",
    "        },\n",
    "        # å•Ÿç”¨æ··åˆæª¢ç´¢ (Hybrid Search) çš„ç¨€ç–å‘é‡é…ç½®\n",
    "        sparse_vectors_config={\n",
    "            \"sparse\": models.SparseVectorParams(modifier=models.Modifier.IDF)\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(f\"ğŸ“Š æº–å‚™è™•ç† {len(documents)} å€‹ Chunks...\")\n",
    "\n",
    "    # 3. æº–å‚™ç´”æ–‡å­—åˆ—è¡¨ä»¥é€²è¡Œ Embedding\n",
    "    # document ç‰©ä»¶ä¸èƒ½ç›´æ¥ embedï¼Œè¦å–å‡º page_content\n",
    "    texts_to_embed = [doc.page_content for doc in documents]\n",
    "\n",
    "    print(\"â³ è¨ˆç®— Embeddings (Dense Vectors)...\")\n",
    "    try:\n",
    "        doc_embeddings = embedding_model.embed_documents(texts_to_embed)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Embedding è¨ˆç®—å¤±æ•—: {e}\")\n",
    "        return\n",
    "\n",
    "    if len(doc_embeddings) != len(documents):\n",
    "        print(\"âŒ Embedding æ•¸é‡èˆ‡æ–‡ä»¶æ•¸é‡ä¸ç¬¦ï¼\")\n",
    "        return\n",
    "\n",
    "    # 4. æº–å‚™å¯«å…¥ Qdrant çš„ Points\n",
    "    points = []\n",
    "    print(\"â³ æ­£åœ¨å°è£è³‡æ–™...\")\n",
    "\n",
    "    for doc, embedding in zip(documents, doc_embeddings):\n",
    "        # ç”¢ç”Ÿ UUID\n",
    "        point_id = uuid.uuid4().hex\n",
    "\n",
    "        # å»ºç«‹ Payload (åŒ…å«æ–‡å­—èˆ‡ä¾†æº metadata)\n",
    "        payload = {\n",
    "            \"text\": doc.page_content,\n",
    "            \"source\": doc.metadata.get(\"source\", \"unknown\"), # æŠŠä¾†æºæª”åå­˜é€²å»\n",
    "            \"page\": doc.metadata.get(\"page\", 0) # å¦‚æœæœ‰çš„è©±\n",
    "        }\n",
    "\n",
    "        # å»ºç«‹ Point\n",
    "        point = models.PointStruct(\n",
    "            id=point_id,\n",
    "            vector={\n",
    "                \"dense\": embedding,\n",
    "                # é€™è£¡ä½¿ç”¨ Qdrant çš„å„ç¨® BM25 æ”¯æ´æ–¹å¼ï¼Œå‚³å…¥ç´”æ–‡å­—\n",
    "                \"sparse\": models.Document(text=doc.page_content, model=\"Qdrant/bm25\"),\n",
    "            },\n",
    "            payload=payload,\n",
    "        )\n",
    "        points.append(point)\n",
    "\n",
    "    # 5. æ‰¹æ¬¡å¯«å…¥ (Upsert)\n",
    "    batch_size = 50\n",
    "    print(f\"â³ é–‹å§‹å¯«å…¥ {len(points)} ç­†è³‡æ–™è‡³ Qdrant...\")\n",
    "\n",
    "    for i in tqdm(range(0, len(points), batch_size), desc=\"Upserting\"):\n",
    "        batch_points = points[i : i + batch_size]\n",
    "        client.upsert(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            points=batch_points\n",
    "        )\n",
    "\n",
    "    print(f\"âœ… è³‡æ–™å¯«å…¥å®Œæˆï¼Collection: {COLLECTION_NAME}\")"
   ],
   "id": "1e76a4e3437e6773",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:14:03.613483Z",
     "start_time": "2026-02-10T16:14:00.916157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"* è¼‰å…¥ Reranker æ¨¡å‹...\")\n",
    "reranker_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    RERANKER_MODEL_PATH, local_files_only=True, trust_remote_code=True\n",
    ")\n",
    "reranker_model = AutoModelForCausalLM.from_pretrained(\n",
    "    RERANKER_MODEL_PATH, local_files_only=True, trust_remote_code=True\n",
    ").to(device_obj).eval()\n",
    "\n",
    "token_false_id = reranker_tokenizer.convert_tokens_to_ids(\"no\")\n",
    "token_true_id = reranker_tokenizer.convert_tokens_to_ids(\"yes\")\n",
    "max_reranker_length = 8192\n",
    "\n",
    "prefix = \"<|im_start|>system\\nJudge whether the Document meets the requirements based on the Query and the Instruct provided. Note that the answer can only be \\\"yes\\\" or \\\"no\\\".<|im_end|>\\n<|im_start|>user\\n\"\n",
    "suffix = \"<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "prefix_tokens = reranker_tokenizer.encode(prefix, add_special_tokens=False)\n",
    "suffix_tokens = reranker_tokenizer.encode(suffix, add_special_tokens=False)"
   ],
   "id": "d85b9bb1e5f3564c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ è¼‰å…¥ Reranker æ¨¡å‹...\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:14:03.644166Z",
     "start_time": "2026-02-10T16:14:03.635676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_rerank_scores(pairs, batch_size=4):\n",
    "    \"\"\"\n",
    "    åˆ†æ‰¹è¨ˆç®— Reranker åˆ†æ•¸ï¼Œé¿å… MPS Out Of Memory\n",
    "    batch_size: å»ºè­°è¨­å°ä¸€é» (ä¾‹å¦‚ 2 æˆ– 4)\n",
    "    \"\"\"\n",
    "    all_scores = []\n",
    "\n",
    "    # ä½¿ç”¨ tqdm é¡¯ç¤º Rerank é€²åº¦ (å¯é¸)\n",
    "    # for i in range(0, len(pairs), batch_size):\n",
    "\n",
    "    for i in range(0, len(pairs), batch_size):\n",
    "        batch_pairs = pairs[i: i + batch_size]\n",
    "\n",
    "        processed_inputs = []\n",
    "        for pair in batch_pairs:\n",
    "            pair_ids = reranker_tokenizer.encode(\n",
    "                pair, add_special_tokens=False, truncation=True,\n",
    "                max_length=max_reranker_length - len(prefix_tokens) - len(suffix_tokens)\n",
    "            )\n",
    "            full_ids = prefix_tokens + pair_ids + suffix_tokens\n",
    "            processed_inputs.append(reranker_tokenizer.decode(full_ids))\n",
    "\n",
    "        inputs = reranker_tokenizer(\n",
    "            processed_inputs, padding=True, truncation=True, return_tensors=\"pt\", max_length=max_reranker_length\n",
    "        )\n",
    "\n",
    "        # ç§»å‹•åˆ° GPU\n",
    "        for key in inputs:\n",
    "            inputs[key] = inputs[key].to(device_obj)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = reranker_model(**inputs).logits[:, -1, :]\n",
    "            scores = logits[:, token_true_id].exp().tolist()\n",
    "            all_scores.extend(scores)\n",
    "\n",
    "        # æ¸…ç† GPU è¨˜æ†¶é«”\n",
    "        del inputs, logits, scores\n",
    "        if device_obj.type == \"mps\":\n",
    "            torch.mps.empty_cache()\n",
    "        elif device_obj.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    return all_scores"
   ],
   "id": "afe6079bc2578181",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:14:03.659307Z",
     "start_time": "2026-02-10T16:14:03.644511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rerank_documents(query, documents):\n",
    "    if not documents: return []\n",
    "\n",
    "    formatted_pairs = [\n",
    "        f\"<Instruct>: æ ¹æ“šæŸ¥è©¢æª¢ç´¢ç›¸é—œæ–‡ä»¶\\n<Query>: {query}\\n<Document>: {doc}\"\n",
    "        for doc in documents\n",
    "    ]\n",
    "\n",
    "    # é€™è£¡å‘¼å«ä¿®æ”¹å¾Œçš„å‡½æ•¸ï¼Œbatch_size è¨­ç‚º 4 (è‹¥é‚„æ˜¯çˆ†è¨˜æ†¶é«”ï¼Œè«‹æ”¹æˆ 2 æˆ– 1)\n",
    "    scores = compute_rerank_scores(formatted_pairs, batch_size=4)\n",
    "\n",
    "    doc_scores = list(zip(documents, scores))\n",
    "    doc_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return doc_scores"
   ],
   "id": "da6d82e39f745e54",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:14:03.663705Z",
     "start_time": "2026-02-10T16:14:03.659642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def query_rewrite(query: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    ä½ æ˜¯ä¸€å€‹æœå°‹å¼•æ“å„ªåŒ–å°ˆå®¶ã€‚è«‹å°‡ä»¥ä¸‹ä½¿ç”¨è€…çš„å•é¡Œæ”¹å¯«ç‚ºæ›´ç²¾ç¢ºã€é©åˆåšèªç¾©æª¢ç´¢çš„é—œéµå­—æŸ¥è©¢ã€‚\n",
    "    ä¿ç•™æ ¸å¿ƒæ„åœ–ï¼Œå»é™¤è´…è©ï¼Œä¸¦é‡å°è‡ªä¾†æ°´å…¬å¸ç›¸é—œæ¥­å‹™é€²è¡Œå„ªåŒ–ã€‚\n",
    "    åªè¼¸å‡ºæ”¹å¯«å¾Œçš„å¥å­ï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡‹ã€‚\n",
    "\n",
    "    ä½¿ç”¨è€…å•é¡Œ: {query}\n",
    "    æ”¹å¯«å¾ŒæŸ¥è©¢:\n",
    "    \"\"\"\n",
    "    rewritten = llm_client.generate(prompt).strip()\n",
    "    return rewritten"
   ],
   "id": "14acbcc257d3f60",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:14:03.676004Z",
     "start_time": "2026-02-10T16:14:03.664040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hybrid_search_with_rerank(query: str, initial_limit=20, final_limit=3):\n",
    "    query_vec = embedding_model.embed_query(query)\n",
    "\n",
    "    try:\n",
    "        response = client.query_points(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            prefetch=[\n",
    "                models.Prefetch(\n",
    "                    query=models.Document(text=query, model=\"Qdrant/bm25\"),\n",
    "                    using=\"sparse\",\n",
    "                    limit=initial_limit,\n",
    "                ),\n",
    "                models.Prefetch(\n",
    "                    query=query_vec,\n",
    "                    using=\"dense\",\n",
    "                    limit=initial_limit,\n",
    "                ),\n",
    "            ],\n",
    "            query=models.FusionQuery(fusion=models.Fusion.RRF),\n",
    "            limit=initial_limit,\n",
    "        )\n",
    "        candidate_docs = [point.payload[\"text\"] for point in response.points]\n",
    "    except Exception as e:\n",
    "        print(f\"Search Error: {e}\")\n",
    "        return []\n",
    "\n",
    "    if not candidate_docs:\n",
    "        return []\n",
    "\n",
    "    # é€™è£¡é€²è¡Œ Rerank\n",
    "    top_results = rerank_documents(query, candidate_docs)[:final_limit]\n",
    "    return top_results"
   ],
   "id": "2d5d6491d8e053ee",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:14:03.693571Z",
     "start_time": "2026-02-10T16:14:03.676348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    print(f\"ğŸ“‚ è®€å– Excel: {PREDICT_INPUT}\")\n",
    "    if not os.path.exists(PREDICT_INPUT):\n",
    "        print(\"âŒ æª”æ¡ˆä¸å­˜åœ¨\")\n",
    "        return\n",
    "    df =  pd.read_csv(PREDICT_INPUT)\n",
    "\n",
    "    if 'q_id' not in df.columns: df['q_id'] = None\n",
    "    if 'answer' not in df.columns: df['answer'] = None\n",
    "\n",
    "    df['q_id'] = df['q_id'].astype('object')\n",
    "    df['answer'] = df['answer'].astype('object')\n",
    "\n",
    "    # ã€æ–°å¢ã€‘ç”¨ä¾†æš«å­˜ Ground Truth (Context) çš„åˆ—è¡¨\n",
    "    ground_truth_list = []\n",
    "\n",
    "    print(\"ğŸš€ é–‹å§‹è™•ç†å•é¡Œ...\")\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        original_question = str(row['questions'])\n",
    "\n",
    "        current_uuid = str(uuid.uuid4())\n",
    "        refined_query = query_rewrite(original_question)\n",
    "        search_results = hybrid_search_with_rerank(refined_query)\n",
    "        retrieval_context = [doc for doc, score in search_results]\n",
    "        context_str = \"\\n\".join(retrieval_context)\n",
    "\n",
    "        ground_truth_list.append({\n",
    "                    \"id\": current_uuid,\n",
    "                    \"questions\": original_question,\n",
    "                    \"contexts\": retrieval_context,  # DeepEval éœ€è¦ list\n",
    "                    \"ground_truth\": \"\"  # é ç•™æ¬„ä½ï¼ŒDeepEval çš„ Recall éœ€è¦é€™å€‹ (æ¨™æº–ç­”æ¡ˆ)\n",
    "                })\n",
    "\n",
    "        qa_prompt = f\"\"\"\n",
    "        ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„å·¥å» è³‡è¨Šéƒ¨åŠ©æ‰‹ã€‚è«‹æ ¹æ“šã€åƒè€ƒè³‡æ–™ã€‘å›ç­”ä½¿ç”¨è€…çš„ã€å•é¡Œã€‘ã€‚\n",
    "\n",
    "        è¦ç¯„ï¼š\n",
    "        1. ç­”æ¡ˆå¿…é ˆåŸºæ–¼åƒè€ƒè³‡æ–™ï¼Œä¸è¦ç·¨é€ ã€‚\n",
    "        2. å¦‚æœåƒè€ƒè³‡æ–™ä¸è¶³ä»¥å›ç­”ï¼Œè«‹å›ç­”ã€Œç›®å‰è³‡è¨Šä¸è¶³ï¼Œå»ºè­°è¯ç¹«å®¢æœã€ã€‚\n",
    "        3. èªæ°£è¦ªåˆ‡ã€å°ˆæ¥­ã€‚\n",
    "\n",
    "        ã€åƒè€ƒè³‡æ–™ã€‘ï¼š\n",
    "        {context_str}\n",
    "\n",
    "        ã€å•é¡Œã€‘ï¼š{original_question}\n",
    "\n",
    "        ã€å›ç­”ã€‘ï¼š\n",
    "        \"\"\"\n",
    "        answer = llm_client.generate(qa_prompt)\n",
    "\n",
    "        # 4. å°‡ Answer å¯«å›åŸæœ¬çš„ DataFrame\n",
    "        df.at[index, 'id'] = current_uuid\n",
    "        df.at[index, 'answer'] = answer\n",
    "\n",
    "    df.to_excel(PREDICT_OUPUT, index=False)\n",
    "    print(f\"âœ… Answer è™•ç†å®Œæˆï¼çµæœå·²å„²å­˜è‡³: {PREDICT_OUPUT}\")\n",
    "\n",
    "    # æª”æ¡ˆ 2ï¼šå­˜ Ground Truth (Context) çš„ CSV\n",
    "    gt_df = pd.DataFrame(ground_truth_list)\n",
    "\n",
    "    # å­˜æˆ CSV (å»ºè­°ç”¨ utf-8-sig ä»¥å…ä¸­æ–‡äº‚ç¢¼)\n",
    "    gt_df.to_csv(\"ground_truth.csv\", index=False, encoding='utf-8-sig')\n",
    "    print(f\"âœ… Ground Truth (Context) å·²å„²å­˜è‡³: ground_truth.csv\")"
   ],
   "id": "c5fa49bcec6e203",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:16:45.452222Z",
     "start_time": "2026-02-10T16:16:35.106495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "68e7788fd8048589",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m----> 2\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[17], line 24\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     22\u001B[0m current_uuid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(uuid\u001B[38;5;241m.\u001B[39muuid4())\n\u001B[1;32m     23\u001B[0m refined_query \u001B[38;5;241m=\u001B[39m query_rewrite(original_question)\n\u001B[0;32m---> 24\u001B[0m search_results \u001B[38;5;241m=\u001B[39m \u001B[43mhybrid_search_with_rerank\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrefined_query\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m retrieval_context \u001B[38;5;241m=\u001B[39m [doc \u001B[38;5;28;01mfor\u001B[39;00m doc, score \u001B[38;5;129;01min\u001B[39;00m search_results]\n\u001B[1;32m     26\u001B[0m context_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(retrieval_context)\n",
      "Cell \u001B[0;32mIn[16], line 2\u001B[0m, in \u001B[0;36mhybrid_search_with_rerank\u001B[0;34m(query, initial_limit, final_limit)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mhybrid_search_with_rerank\u001B[39m(query: \u001B[38;5;28mstr\u001B[39m, initial_limit\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m, final_limit\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m):\n\u001B[0;32m----> 2\u001B[0m     query_vec \u001B[38;5;241m=\u001B[39m \u001B[43membedding_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m      5\u001B[0m         response \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mquery_points(\n\u001B[1;32m      6\u001B[0m             collection_name\u001B[38;5;241m=\u001B[39mCOLLECTION_NAME,\n\u001B[1;32m      7\u001B[0m             prefetch\u001B[38;5;241m=\u001B[39m[\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     20\u001B[0m             limit\u001B[38;5;241m=\u001B[39minitial_limit,\n\u001B[1;32m     21\u001B[0m         )\n",
      "Cell \u001B[0;32mIn[8], line 28\u001B[0m, in \u001B[0;36mCustomAPIEmbeddings.embed_query\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21membed_query\u001B[39m(\u001B[38;5;28mself\u001B[39m, text: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[\u001B[38;5;28mfloat\u001B[39m]:\n\u001B[0;32m---> 28\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_api\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m results \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(results) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     30\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m results[\u001B[38;5;241m0\u001B[39m]\n",
      "Cell \u001B[0;32mIn[8], line 13\u001B[0m, in \u001B[0;36mCustomAPIEmbeddings._call_api\u001B[0;34m(self, texts)\u001B[0m\n\u001B[1;32m      6\u001B[0m data \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtexts\u001B[39m\u001B[38;5;124m\"\u001B[39m: texts,\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnormalize\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch_size\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m32\u001B[39m\n\u001B[1;32m     10\u001B[0m }\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 13\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mrequests\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpost\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapi_url\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m60\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m200\u001B[39m:\n\u001B[1;32m     15\u001B[0m         result \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mjson()\n",
      "File \u001B[0;32m~/.mamba/envs/ai_for_course_py310/lib/python3.10/site-packages/requests/api.py:115\u001B[0m, in \u001B[0;36mpost\u001B[0;34m(url, data, json, **kwargs)\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpost\u001B[39m(url, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, json\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    104\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a POST request.\u001B[39;00m\n\u001B[1;32m    105\u001B[0m \n\u001B[1;32m    106\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 115\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpost\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.mamba/envs/ai_for_course_py310/lib/python3.10/site-packages/requests/api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[0;34m(method, url, **kwargs)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.mamba/envs/ai_for_course_py310/lib/python3.10/site-packages/requests/sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    587\u001B[0m }\n\u001B[1;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m~/.mamba/envs/ai_for_course_py310/lib/python3.10/site-packages/requests/sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[0;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[1;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[0;32m~/.mamba/envs/ai_for_course_py310/lib/python3.10/site-packages/requests/adapters.py:644\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    641\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m TimeoutSauce(connect\u001B[38;5;241m=\u001B[39mtimeout, read\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[1;32m    643\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 644\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    645\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    646\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    647\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    648\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    649\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    650\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    651\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    652\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    653\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    654\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    655\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    656\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    658\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    659\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "File \u001B[0;32m~/.mamba/envs/ai_for_course_py310/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[1;32m    784\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    786\u001B[0m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[0;32m--> 787\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    788\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    789\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    790\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    791\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    792\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    793\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    794\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    795\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    796\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresponse_conn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresponse_conn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    797\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreload_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    798\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    799\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mresponse_kw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    800\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    802\u001B[0m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n\u001B[1;32m    803\u001B[0m clean_exit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/.mamba/envs/ai_for_course_py310/lib/python3.10/site-packages/urllib3/connectionpool.py:534\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[1;32m    532\u001B[0m \u001B[38;5;66;03m# Receive the response from the server\u001B[39;00m\n\u001B[1;32m    533\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 534\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    535\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (BaseSSLError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    536\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mread_timeout)\n",
      "File \u001B[0;32m~/.mamba/envs/ai_for_course_py310/lib/python3.10/site-packages/urllib3/connection.py:565\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    562\u001B[0m _shutdown \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshutdown\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    564\u001B[0m \u001B[38;5;66;03m# Get the response from http.client.HTTPConnection\u001B[39;00m\n\u001B[0;32m--> 565\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    567\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    568\u001B[0m     assert_header_parsing(httplib_response\u001B[38;5;241m.\u001B[39mmsg)\n",
      "File \u001B[0;32m~/.mamba/envs/ai_for_course_py310/lib/python3.10/http/client.py:1375\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1373\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1374\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1375\u001B[0m         \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbegin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1376\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[1;32m   1377\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/.mamba/envs/ai_for_course_py310/lib/python3.10/http/client.py:318\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    316\u001B[0m \u001B[38;5;66;03m# read until we get a non-100 response\u001B[39;00m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 318\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n\u001B[1;32m    320\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/.mamba/envs/ai_for_course_py310/lib/python3.10/http/client.py:279\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 279\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_MAXLINE\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso-8859-1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    280\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) \u001B[38;5;241m>\u001B[39m _MAXLINE:\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus line\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.mamba/envs/ai_for_course_py310/lib/python3.10/socket.py:717\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    715\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    716\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 717\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    718\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    719\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
